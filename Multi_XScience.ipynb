{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN58M3cONH+5HrJnbWT6S99",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikitasTsingenopoulos/Multi-XSience/blob/main/Multi_XScience.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G7hFi3K9kwD"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets\n",
        "!pip install -U evaluate\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (AutoTokenizer, LEDConfig, LEDForConditionalGeneration)\n",
        "from datasets import load_dataset,Dataset, DatasetDict\n",
        "import torch"
      ],
      "metadata": {
        "id": "wQ9inGBq9sZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yaolu/Multi-XScience.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "UN66N1e0-BlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip /content/Multi-XScience/data/test.json.gz\n",
        "!gunzip /content/Multi-XScience/data/train.json.gz\n",
        "!gunzip /content/Multi-XScience/data/val.json.gz"
      ],
      "metadata": {
        "id": "Sdfe2LGm-d2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "train_path = '/content/Multi-XScience/data/train.json'\n",
        "val_path = '/content/Multi-XScience/data/val.json'\n",
        "test_path = '/content/Multi-XScience/data/test.json'\n",
        "\n",
        "\n",
        "with open(train_path, 'r', encoding='utf-8') as f:\n",
        "  dataset_train = json.load(f)\n",
        "\n",
        "with open(val_path, 'r', encoding='utf-8') as f:\n",
        "  dataset_val = json.load(f)\n",
        "\n",
        "with open(test_path, 'r', encoding='utf-8') as f:\n",
        "  dataset_test = json.load(f)"
      ],
      "metadata": {
        "id": "W4iF2eW5-pTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('allenai/PRIMERA')\n",
        "\n",
        "config=LEDConfig.from_pretrained('allenai/PRIMERA')\n",
        "\n",
        "model = LEDForConditionalGeneration.from_pretrained('allenai/PRIMERA')\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "PAD_TOKEN_ID = tokenizer.pad_token_id\n",
        "DOCSEP_TOKEN_ID = tokenizer.convert_tokens_to_ids(\"<doc-sep>\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "b8KGB4ZV-iU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_document(documents):\n",
        "    input_ids_all = []\n",
        "    for data in documents:\n",
        "        article = data.replace(\"\\n\", \" \")\n",
        "        article = \" \".join(article.split())\n",
        "        input_ids = tokenizer.encode(\n",
        "            article,\n",
        "            truncation=True,\n",
        "            max_length=4096,\n",
        "        )[1:-1]\n",
        "        input_ids = (\n",
        "            [tokenizer.bos_token_id]\n",
        "            + input_ids\n",
        "            + [tokenizer.eos_token_id]\n",
        "        )\n",
        "        input_ids_all.append(torch.tensor(input_ids))\n",
        "\n",
        "    input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "        input_ids_all, batch_first=True, padding_value=PAD_TOKEN_ID\n",
        "    )\n",
        "    return input_ids"
      ],
      "metadata": {
        "id": "L5GYBEOlAmM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_process(batch):\n",
        "\n",
        "    ref_abstracts = []\n",
        "    for ref_dict in batch[\"ref_abstract\"]:\n",
        "        context_abstracts = []\n",
        "        for inner in ref_dict.values():\n",
        "            if isinstance(inner, dict) and \"abstract\" in inner:\n",
        "                context_abstracts.append(inner[\"abstract\"])\n",
        "        # Join all abstracts for this example\n",
        "        ref_abstracts.append(\" \".join(context_abstracts))\n",
        "\n",
        "\n",
        "    inputs = [a + \" \" + r\n",
        "              for a, r in zip(batch['abstract'], ref_abstracts)\n",
        "    ]\n",
        "    input_ids=process_document(inputs)\n",
        "    # get the input ids and attention masks together\n",
        "    global_attention_mask = torch.zeros_like(input_ids).to(input_ids.device)\n",
        "    # put global attention on <s> token\n",
        "\n",
        "    global_attention_mask[:, 0] = 1\n",
        "    global_attention_mask[input_ids == DOCSEP_TOKEN_ID] = 1\n",
        "    generated_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        global_attention_mask=global_attention_mask,\n",
        "        use_cache=True,\n",
        "        max_length=1024,\n",
        "        num_beams=5,\n",
        "    )\n",
        "    generated_str = tokenizer.batch_decode(\n",
        "            generated_ids.tolist(), skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "    result={}\n",
        "    result['generated_summaries'] = generated_str\n",
        "    result['gt_summaries']=batch['related_work'] # Use the correctly extracted abstracts for the batch\n",
        "    return result"
      ],
      "metadata": {
        "id": "jR5MK-hxMy01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "test_dataset = Dataset.from_list(dataset_test)\n",
        "docs = random.choices(range(len(dataset_test)),k=5)\n",
        "docs"
      ],
      "metadata": {
        "id": "C8Q1Ie6OEmt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_small = test_dataset.select(docs)\n",
        "result_small = dataset_small.map(batch_process, batched=True, batch_size=2)"
      ],
      "metadata": {
        "id": "8PxPUjG9V9io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "FoiWK7x8ftpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "for summ in result_small['generated_summaries']:\n",
        "    wrapped_summ = textwrap.fill(summ, 160)\n",
        "    print(wrapped_summ)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PKY6SSGw19sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score=rouge.compute(predictions=result_small[\"generated_summaries\"], references=result_small[\"gt_summaries\"])\n",
        "\n",
        "print(f\"ROUGE-1: {score['rouge1']:.4f}\")\n",
        "print(f\"ROUGE-2: {score['rouge2']:.4f}\")\n",
        "print(f\"ROUGE-L: {score['rougeL']:.4f}\")"
      ],
      "metadata": {
        "id": "3O0J9Abd2Ca4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = dataset_small[4]\n",
        "\n",
        "display(example)\n",
        "#display(example_summ)"
      ],
      "metadata": {
        "id": "1iowq_A22I8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H4zHiA30Rqrp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}